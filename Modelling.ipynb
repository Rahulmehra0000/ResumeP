{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "kfold = KFold(5)\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Datadirectory = 'Resumes2'\n",
    "classes = ['Peoplesoft resumes','React resumes','SQL Developer Lightning insight','workday resumes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "key = []\n",
    "def create_training_data():\n",
    "    for category in classes:\n",
    "        path = os.path.join(Datadirectory,category)\n",
    "        class_num = classes.index(category)\n",
    "        for resume in os.listdir(path):\n",
    "            label.append(category)\n",
    "            key.append(resume)            \n",
    "\n",
    "create_training_data()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: \n",
      "['Peoplesoft resumes', 'Peoplesoft resumes', 'Peoplesoft resumes', 'Peoplesoft resumes', 'Peoplesoft resumes']\n",
      "Length of Labels: 78\n",
      "Keys: \n",
      "['Peoplesoft Admin_AnubhavSingh.docx', 'Peoplesoft Admin_G Ananda Rayudu.doc', 'Peoplesoft Admin_Gangareddy.doc', 'Peoplesoft Admin_Murali.docx', 'Peoplesoft Admin_Priyanka Ramadoss.doc']\n",
      "Length of Keys: 78\n"
     ]
    }
   ],
   "source": [
    "print('Labels: \\n{}\\nLength of Labels: {}\\nKeys: \\n{}\\nLength of Keys: {}'.format(label[:5], len(label), key[:5], len(key)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Dictionary of Key and Label\n",
    "labelDict = dict(zip(key, label))\n",
    "\n",
    "# Sorting it in alphabetical order of keys\n",
    "finalDict = {}\n",
    "for i in sorted(labelDict.keys()):\n",
    "    finalDict[i] = labelDict[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Number</th>\n",
       "      <th>Email ID</th>\n",
       "      <th>Links</th>\n",
       "      <th>Education</th>\n",
       "      <th>Skills</th>\n",
       "      <th>University Name</th>\n",
       "      <th>Years of Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANIL KUMAR</td>\n",
       "      <td>['+911234567890']</td>\n",
       "      <td>ijayawadaabc@xyz.com</td>\n",
       "      <td>['https://www.linkedin.com/fake', 'https://www...</td>\n",
       "      <td>[('MS', '2016'), 'BTech']</td>\n",
       "      <td>['Sql', 'Debugging', 'Technical', 'Windows', '...</td>\n",
       "      <td>['Velagapudi siddhartha engineering college']</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aradhana Tripathi</td>\n",
       "      <td>['+911234567890']</td>\n",
       "      <td>niversity.abc@xyz.com</td>\n",
       "      <td>['https://www.linkedin.com/fake', 'https://www...</td>\n",
       "      <td>['MS', 'MCA']</td>\n",
       "      <td>['Sql', 'Acquisition', 'Stakeholder management...</td>\n",
       "      <td>['AKS University', ' IIIT ']</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Database Engineer</td>\n",
       "      <td>['+911234567890']</td>\n",
       "      <td>knowledge.abc@xyz.com</td>\n",
       "      <td>['https://www.linkedin.com/fake', 'https://www...</td>\n",
       "      <td>['MS', ('SSC', '2011')]</td>\n",
       "      <td>['Sql', 'Servers', 'Technical', 'Programming',...</td>\n",
       "      <td>['Create ETL Jobs And Monitoring The Jobs ACAD...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chinna Subbarayudu</td>\n",
       "      <td>['+911234567890']</td>\n",
       "      <td>2abc@xyz.com</td>\n",
       "      <td>['https://www.linkedin.com/fake', 'https://www...</td>\n",
       "      <td>['MS']</td>\n",
       "      <td>['Policies', 'Sql', 'Web services', 'Prototypi...</td>\n",
       "      <td>['Yogi Vemana University']</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gopi Krishna</td>\n",
       "      <td>['+911234567890']</td>\n",
       "      <td>annada.abc@xyz.com</td>\n",
       "      <td>['https://www.linkedin.com/fake', 'https://www...</td>\n",
       "      <td>['Bachelor of Degree from JNTU - K University ...</td>\n",
       "      <td>['Specifications', 'Technical', 'Communication...</td>\n",
       "      <td>['JNTU']</td>\n",
       "      <td>3+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name             Number               Email ID  \\\n",
       "0          ANIL KUMAR  ['+911234567890']   ijayawadaabc@xyz.com   \n",
       "1   Aradhana Tripathi  ['+911234567890']  niversity.abc@xyz.com   \n",
       "2   Database Engineer  ['+911234567890']  knowledge.abc@xyz.com   \n",
       "3  Chinna Subbarayudu  ['+911234567890']           2abc@xyz.com   \n",
       "4        Gopi Krishna  ['+911234567890']     annada.abc@xyz.com   \n",
       "\n",
       "                                               Links  \\\n",
       "0  ['https://www.linkedin.com/fake', 'https://www...   \n",
       "1  ['https://www.linkedin.com/fake', 'https://www...   \n",
       "2  ['https://www.linkedin.com/fake', 'https://www...   \n",
       "3  ['https://www.linkedin.com/fake', 'https://www...   \n",
       "4  ['https://www.linkedin.com/fake', 'https://www...   \n",
       "\n",
       "                                           Education  \\\n",
       "0                          [('MS', '2016'), 'BTech']   \n",
       "1                                      ['MS', 'MCA']   \n",
       "2                            ['MS', ('SSC', '2011')]   \n",
       "3                                             ['MS']   \n",
       "4  ['Bachelor of Degree from JNTU - K University ...   \n",
       "\n",
       "                                              Skills  \\\n",
       "0  ['Sql', 'Debugging', 'Technical', 'Windows', '...   \n",
       "1  ['Sql', 'Acquisition', 'Stakeholder management...   \n",
       "2  ['Sql', 'Servers', 'Technical', 'Programming',...   \n",
       "3  ['Policies', 'Sql', 'Web services', 'Prototypi...   \n",
       "4  ['Specifications', 'Technical', 'Communication...   \n",
       "\n",
       "                                     University Name Years of Experience  \n",
       "0      ['Velagapudi siddhartha engineering college']                 2.4  \n",
       "1                       ['AKS University', ' IIIT ']                   4  \n",
       "2  ['Create ETL Jobs And Monitoring The Jobs ACAD...                 NaN  \n",
       "3                         ['Yogi Vemana University']                 5.1  \n",
       "4                                           ['JNTU']                  3+  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Details dataframe\n",
    "df = pd.read_csv('FinalDF.csv')\n",
    "df = df.iloc[:,1:]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name                    0\n",
       "Number                  0\n",
       "Email ID                0\n",
       "Links                   0\n",
       "Education              11\n",
       "Skills                  0\n",
       "University Name         9\n",
       "Years of Experience     9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(df, open('model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model to compare the results\n",
    "model = pickle.load(open('model.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Dataframe for Modelling\n",
    "model_df = pd.DataFrame(df['Skills'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['Sql', 'Debugging', 'Technical', 'Windows', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['Sql', 'Acquisition', 'Stakeholder management...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['Sql', 'Servers', 'Technical', 'Programming',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['Policies', 'Sql', 'Web services', 'Prototypi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['Specifications', 'Technical', 'Communication...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Skills\n",
       "0  ['Sql', 'Debugging', 'Technical', 'Windows', '...\n",
       "1  ['Sql', 'Acquisition', 'Stakeholder management...\n",
       "2  ['Sql', 'Servers', 'Technical', 'Programming',...\n",
       "3  ['Policies', 'Sql', 'Web services', 'Prototypi...\n",
       "4  ['Specifications', 'Technical', 'Communication..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Dataframe for Modelling\n",
    "model_df = pd.DataFrame(df['Name'])\n",
    "model_df['Skills'] = df['Skills']\n",
    "model_df['Label'] = labelDict.values()\n",
    "model_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df[50:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing it in a csv file\n",
    "# model_df.to_csv('ResumeClassificationDF.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = pd.read_csv('ResumeClassificationDF.csv')\n",
    "model_df = model_df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmetizer = WordNetLemmatizer()\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "cleaned_data = []\n",
    "def clean_data(text):\n",
    "    text_clean = []\n",
    "    text_tokens = word_tokenize(text)\n",
    "    for word in text_tokens:\n",
    "        if (word not in stop_words and # remove stopwords\n",
    "            word not in string.punctuation): # remove punctuation\n",
    "            stem_word = lemmetizer.lemmatize(word) # stemming word\n",
    "            text_clean.append(stem_word)\n",
    "    list_to_str = ' '.join([str(ele) for ele in text_clean])\n",
    "    list_to_str = re.sub(\"'\",'',list_to_str)   \n",
    "    return list_to_str.lower() \n",
    "\n",
    " # Calling Function\n",
    "for text in model_df['Skills']:\n",
    "    cleaned_data.append(clean_data(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df['Cleaned Skills'] = cleaned_data\n",
    "model_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization and Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV = CountVectorizer(stop_words = 'english')\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoder\n",
    "model_df['Label'] = le.fit_transform(model_df['Label'])\n",
    "\n",
    "\n",
    "# Bag of Words Vectorization\n",
    "# model_df['Vectorized Skills'] = CV.fit_transform(model_df['Cleaned Skills'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model_df['Cleaned Skills'].values\n",
    "y = model_df['Label'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size= 0.20, random_state= 42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()\n",
    "X_train_CV = CV.fit_transform(X_train)\n",
    "mnb.fit(X_train_CV, y_train)\n",
    "X_test_CV = CV.transform(X_test)\n",
    "y_pred = mnb.predict(X_test_CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_pred, y_test)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_rf = RandomForestClassifier()\n",
    "clf_rf.fit(X_train_CV, y_train)\n",
    "y_pred = clf_rf.predict(X_test_CV)\n",
    "accuracy_score(y_pred, y_test)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute Precision, Recall and F1 score\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score\n",
    "precision, recall, f1, models, accuracy = [], [],[], [], []\n",
    "def get_pre_rec_f1(model_name, model,X_test,y_test):\n",
    "    models.append(model_name)\n",
    "    y_pred = model.predict(X_test)\n",
    "    precision_Score = precision_score(y_test, y_pred, average = 'weighted')\n",
    "    recall_Score = recall_score(y_test, y_pred, average = 'weighted')\n",
    "    F1 = 2 * (precision_Score * recall_Score) / (precision_Score + recall_Score)\n",
    "    accuracy_Score = accuracy_score(y_test, y_pred)\n",
    "    precision.append(precision_Score)\n",
    "    recall.append(recall_Score)\n",
    "    f1.append(F1)\n",
    "    accuracy.append(accuracy_Score)\n",
    "    df = pd.DataFrame(models,columns=['Model'] )\n",
    "    df['Accuracy'] = accuracy\n",
    "    df['Precision'] = precision\n",
    "    df['Recall'] = recall\n",
    "    df['F1 Score'] = f1\n",
    "    return df\n",
    "    # print(f'Precision:{precision:.3f}\\nRecall:{recall:.3f}\\nF1 score:{F1:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = get_pre_rec_f1('Multinomial Naive Bayes', mnb, X_test_CV, y_test)\n",
    "eval_df = get_pre_rec_f1('Random Forest Classifier', clf_rf, X_test_CV, y_test)\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model_df, open('model.pkl_n','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'model_n.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-47ceccd9f7f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Loading model to compare the results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model_n.pkl'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model_n.pkl'"
     ]
    }
   ],
   "source": [
    "# Loading model to compare the results\n",
    "model = pickle.load(open('model_n.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
